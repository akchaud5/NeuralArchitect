{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project: MNIST Classification with CNN\n",
    "\n",
    "This notebook demonstrates how to use the neural networks framework to train a CNN model on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.models.cnn_model import CNNModel\n",
    "from src.utils.trainer import Trainer\n",
    "from src.utils.metrics import MetricsTracker\n",
    "from src.config.config_manager import ConfigManager, get_default_config\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use the MNIST dataset for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "examples = iter(train_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "# Plot some examples\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "    plt.title(f\"Label: {example_targets[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and Create the Model\n",
    "\n",
    "Let's use our configuration manager to set up the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the default configuration\n",
    "config_manager = ConfigManager(default_config=get_default_config())\n",
    "config = config_manager.get_all()\n",
    "\n",
    "# Update configuration for MNIST\n",
    "config_manager.set('model.input_channels', 1)  # MNIST images are grayscale\n",
    "config_manager.set('model.num_classes', 10)  # 10 digits\n",
    "config_manager.set('cnn.conv_channels', [32, 64, 128])  # CNN architecture\n",
    "config_manager.set('cnn.fc_units', [512, 128])  # Fully-connected layers\n",
    "config_manager.set('training.num_epochs', 5)  # Number of epochs\n",
    "config_manager.set('training.learning_rate', 0.001)  # Learning rate\n",
    "\n",
    "# Create model configuration\n",
    "model_config = {\n",
    "    'input_channels': config['model']['input_channels'],\n",
    "    'num_classes': config['model']['num_classes'],\n",
    "    'conv_channels': config['cnn']['conv_channels'],\n",
    "    'fc_units': config['cnn']['fc_units'],\n",
    "    'dropout_rate': config['model']['dropout_rate']\n",
    "}\n",
    "\n",
    "# Create the model\n",
    "model = CNNModel(model_config)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"CNN Model created with {model.get_parameter_count():,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the Trainer\n",
    "\n",
    "Now let's set up the training configuration and create our trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer configuration\n",
    "trainer_config = {\n",
    "    'learning_rate': config['training']['learning_rate'],\n",
    "    'weight_decay': config['training']['weight_decay'],\n",
    "    'num_epochs': config['training']['num_epochs'],\n",
    "    'batch_size': batch_size,\n",
    "    'optimizer': 'adam',  # Use Adam optimizer\n",
    "    'scheduler': 'cosine',  # Use cosine annealing scheduler\n",
    "    'criterion': 'cross_entropy',  # Use cross-entropy loss\n",
    "    'clip_grad_norm': 1.0,  # Clip gradients\n",
    "    'early_stopping_patience': 5,  # Stop training if no improvement after 5 epochs\n",
    "    'checkpoint_dir': '../checkpoints',  # Directory to save model checkpoints\n",
    "    'save_best_only': True  # Only save the best model\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(trainer_config['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "# Create the trainer\n",
    "trainer = Trainer(model, trainer_config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Now we're ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(f\"Starting training for {trainer_config['num_epochs']} epochs...\")\n",
    "stats = trainer.train(train_loader, test_loader)\n",
    "\n",
    "# Print best results\n",
    "print(f\"\\nBest validation accuracy: {stats['best_val_acc']:.2f}%\")\n",
    "print(f\"Best validation loss: {stats['best_val_loss']:.4f} (epoch {stats['best_epoch']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Results\n",
    "\n",
    "Let's visualize how the training and validation metrics changed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(stats['train_loss']) + 1), stats['train_loss'], label='Training Loss')\n",
    "plt.plot(range(1, len(stats['val_loss']) + 1), stats['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(stats['train_acc']) + 1), stats['train_acc'], label='Training Accuracy')\n",
    "plt.plot(range(1, len(stats['val_acc']) + 1), stats['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Best Model and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model_path = os.path.join(trainer_config['checkpoint_dir'], 'best_model.pt')\n",
    "model.load(best_model_path)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating the best model on the test set...\")\n",
    "test_loss, test_acc = trainer.evaluate(test_loader, desc=\"Test\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions\n",
    "\n",
    "Let's visualize some predictions from our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_examples = iter(test_loader)\n",
    "test_images, test_labels = next(test_examples)\n",
    "\n",
    "# Move to device\n",
    "test_images = test_images.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "# Get predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Move tensors back to CPU for plotting\n",
    "test_images = test_images.cpu()\n",
    "test_labels = test_labels.cpu()\n",
    "predicted = predicted.cpu()\n",
    "\n",
    "# Plot images with predictions\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(15):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.imshow(test_images[i][0], cmap='gray')\n",
    "    title_color = 'green' if predicted[i] == test_labels[i] else 'red'\n",
    "    plt.title(f\"True: {test_labels[i]}, Pred: {predicted[i]}\", color=title_color)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Detailed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a metrics tracker\n",
    "metrics_tracker = MetricsTracker(task_type='classification', n_classes=10)\n",
    "\n",
    "# Evaluate the model and track metrics\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Update the metrics tracker\n",
    "        metrics_tracker.update(labels, predicted, probabilities)\n",
    "\n",
    "# Print the metrics\n",
    "metrics_tracker.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model Configuration\n",
    "\n",
    "Let's save the model configuration for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the configuration to a file\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "config_path = '../outputs/mnist_cnn_config.yaml'\n",
    "config_manager.save_config(config_path)\n",
    "print(f\"Configuration saved to {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have demonstrated how to use the neural networks framework to:\n",
    "\n",
    "1. Load and prepare data using PyTorch's dataset and dataloader utilities\n",
    "2. Configure and create a CNN model using our model implementation\n",
    "3. Train the model using our training utilities\n",
    "4. Evaluate the model and visualize the results\n",
    "5. Save the model and configuration for future use\n",
    "\n",
    "This framework provides a flexible and powerful foundation for implementing and experimenting with different neural network architectures and training strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}